{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load CPT Codes from Excel File\n",
    "cpt_file = \"cpt_codes.xlsx\"\n",
    "cpt_data = pd.read_excel(cpt_file)\n",
    "\n",
    "# Extract codes and descriptions\n",
    "cpt_descriptions = cpt_data[\"Description\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_text = \"Behavioral Health Support for Primary Care Integrated, Virtual Mental Health Care for Family Medicine, Pediatrics and OBGYN OUR  MISSION Increasing Access to Mental Health Services in Underresourced Areas  While about a quarter of adults have a mental illness, 50 %  of the US population lives in a mental health shortage area.  [company name] sets out to help patients in areas where support is otherwise unavailable.  THE PROBLEM 25% 80% 50%  of PCP visits involve mental health Patients overwhelmingly bring their mental health concerns to primary care providers instead of going directly to specialty care. PCPs act as the de facto triage point but have limited support.of patients with mental health concerns seek support from primary care PCPs work in 15-minute appointments and typically have limited resources and training, putting a strain both on them and their patients.Of the US population lives in a mental health shortage area Given massive shortages, there are frequently 6 +  month waitlists for patients who need specialty mental health support.Communities Lack Access to Mental Healthcare Patients look to primary care as their front line of support, however providers are poorly equipped Collaborative Care ([name]) [name]  integrates physical and mental health care in the primary care setting through counseling and consulting psychiatry.  There have been 80 +  academic studies *  showing :  [name] is highly effective (2x vs. usual care) 1. [name] reduces cost of care substantially 2. [name] drives up patient and provider satisfaction 3. *See details here THE CARE MODEL [company name] Has Aligned Incentives With Primary Care Clinics Improve Outcomes  & Patient Satisfaction Studies of the [name] Model have shown that it is more than 2x as effective as usual care in driving mental health symptoms to remission.  Moreover, 75 %  of patients who are treated through [name] models are highly satisfied with their care. Activate A New  FFS Revenue Stream Collaborative care can generate significant new revenue for partner practices through FFS reimbursement. [company name] generates ~$ 10k in contrbution margin per engaged PCP / year. Improve Risk Adjustments & Reduce Cost of Care We can drive an additional increase in revenue through refining mental health diagnoses and improving risk adjustments. Additionally, [name] has been proven to reduce patient cost of care by $ 3,400 over 4 years. VALUE PROPOSITION. Thank you For more info, contact : [email]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioBert & ClinicalBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# BioBERT\n",
    "biobert_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "biobert_model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "# ClinicalBERT\n",
    "clinicalbert_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "clinicalbert_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Relevant CPT Codes:\n",
      "        Code                                        Description  Similarity\n",
      "10658  3066F  Nephropathy is a kidney disease, which may occ...    0.924085\n",
      "5328   59426  This service is considered a mini global code ...    0.920627\n",
      "5327   59425  This service is considered a mini global code ...    0.917729\n",
      "7062   80344  The lab analyst measures the amount of or dete...    0.913344\n",
      "7190   80344  The lab analyst measures the amount of or dete...    0.913344\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text, tokenizer, model, max_length=128):\n",
    "    \"\"\"Generate [CLS] token embeddings for the input text.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Return the embedding for the [CLS] token\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze(0).numpy()\n",
    "\n",
    "# Step 4: Generate Embeddings for the Pitch Text and CPT Descriptions\n",
    "pitch_embedding = get_embedding(pitch_text, clinicalbert_tokenizer, clinicalbert_model)\n",
    "\n",
    "cpt_embeddings = []\n",
    "for description in cpt_descriptions:\n",
    "    cpt_embeddings.append(get_embedding(description, clinicalbert_tokenizer, clinicalbert_model))\n",
    "\n",
    "# Convert CPT embeddings to a numpy array for similarity computation\n",
    "import numpy as np\n",
    "cpt_embeddings = np.array(cpt_embeddings)\n",
    "\n",
    "# Step 5: Compute Cosine Similarities\n",
    "similarities = cosine_similarity([pitch_embedding], cpt_embeddings).flatten()\n",
    "\n",
    "# Step 6: Find the Top N Matches\n",
    "top_n = 5\n",
    "top_indices = similarities.argsort()[-top_n:][::-1]  # Indices of top N most similar descriptions\n",
    "top_matches = cpt_data.iloc[top_indices].copy()\n",
    "top_matches[\"Similarity\"] = similarities[top_indices]\n",
    "\n",
    "# Step 7: Display the Top Matches\n",
    "print(\"Top Relevant CPT Codes:\")\n",
    "print(top_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Helper Functions for Embedding Generation\n",
    "def generate_embeddings(text, tokenizer, model):\n",
    "    \"\"\"Generates embeddings for the input text using the given tokenizer and model.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Use [CLS] token embedding as the sentence embedding\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "    return cls_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate Embeddings for Pitch Deck Text and CPT Descriptions\n",
    "def get_embeddings_for_cpt(cpt_descriptions, tokenizer, model):\n",
    "    \"\"\"Generates embeddings for all CPT descriptions.\"\"\"\n",
    "    cpt_embeddings = []\n",
    "    for desc in cpt_descriptions:\n",
    "        embedding = generate_embeddings(desc, tokenizer, model)\n",
    "        cpt_embeddings.append(embedding)\n",
    "    return torch.tensor(cpt_embeddings).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/var/folders/nl/c2qd572x47jc6xs5b3g_cp800000gn/T/ipykernel_78668/593546199.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686130/work/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  return torch.tensor(cpt_embeddings).squeeze()\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for pitch text and CPT codes\n",
    "biobert_pitch_embedding = generate_embeddings(pitch_text, biobert_tokenizer, biobert_model)\n",
    "biobert_cpt_embeddings = get_embeddings_for_cpt(cpt_descriptions, biobert_tokenizer, biobert_model)\n",
    "\n",
    "clinicalbert_pitch_embedding = generate_embeddings(pitch_text, clinicalbert_tokenizer, clinicalbert_model)\n",
    "clinicalbert_cpt_embeddings = get_embeddings_for_cpt(cpt_descriptions, clinicalbert_tokenizer, clinicalbert_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Calculate Cosine Similarities\n",
    "def find_top_matches(pitch_embedding, cpt_embeddings, cpt_data, top_n=5):\n",
    "    \"\"\"Finds the top N CPT codes most similar to the input pitch text.\"\"\"\n",
    "    similarities = cosine_similarity(pitch_embedding, cpt_embeddings)\n",
    "    top_indices = similarities.argsort()[0][-top_n:][::-1]\n",
    "    top_matches = cpt_data.iloc[top_indices]\n",
    "    top_matches[\"Similarity\"] = similarities[0, top_indices]\n",
    "    return top_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Matches using BioBERT:\n",
      "       Code                                        Description  Similarity\n",
      "3481  37215  The provider places an intravascular stent int...    0.871257\n",
      "6984  78812  PET scans are highly effective in the detectio...    0.868899\n",
      "4738  51595  In this procedure, the provider surgically rem...    0.863706\n",
      "6988  78816  The patient is injected with a radiopharmaceut...    0.863442\n",
      "9808  95941  A provider other than the surgeon or anesthesi...    0.860780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/c2qd572x47jc6xs5b3g_cp800000gn/T/ipykernel_78668/3507439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_matches[\"Similarity\"] = similarities[0, top_indices]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BioBERT Results\n",
    "print(\"Top Matches using BioBERT:\")\n",
    "biobert_top_matches = find_top_matches(biobert_pitch_embedding, biobert_cpt_embeddings, cpt_data)\n",
    "print(biobert_top_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Matches using ClinicalBERT:\n",
      "        Code                                        Description  Similarity\n",
      "10907  0020M  This is an administrative multianalyte assay w...    0.907281\n",
      "6803   77300  Radiation therapy is one of the most effective...    0.896859\n",
      "10229  99392  Preventive medicine services are provided to i...    0.894350\n",
      "10228  99391  Preventive medicine services are provided to i...    0.894350\n",
      "7649   81560  The lab analyst performs a blood test to evalu...    0.893371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/c2qd572x47jc6xs5b3g_cp800000gn/T/ipykernel_78668/3507439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_matches[\"Similarity\"] = similarities[0, top_indices]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ClinicalBERT Results\n",
    "print(\"Top Matches using ClinicalBERT:\")\n",
    "clinicalbert_top_matches = find_top_matches(clinicalbert_pitch_embedding, clinicalbert_cpt_embeddings, cpt_data)\n",
    "print(clinicalbert_top_matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: 212, Description: The provider performs anesthesia services for a patient undergoing intracranial procedures involving subdural taps. In this procedure, another provider removes a little fluid from the subdural space, the fluid filled space in between the outer and middle membrane layers covering the brain. The surgical provider performs the procedure to decrease the excess intracranial fluid pressure being exerted on the brain tissues., Score: 86\n",
      "Code: 474, Description: The provider performs anesthesia services for a patient undergoing a partial rib resection in which the surgical provider removes a portion of the ribs. The radical procedure involves other extensive measures for treating conditions such as pectus excavatum, which is a hollow depression in the center of the lower chest., Score: 86\n",
      "Code: 563, Description: The provider performs anesthesia services for a patient undergoing a procedure involving the heart, the sac around the heart, and the great vessels of the chest, such as the aorta, its major branches, and the major pulmonary vessels. The procedure requires a pump oxygenator to take on the work of the heart and lungs. The procedure also involves hypothermic circulatory arrest, which cools the body to stop blood circulation without endangering the patient., Score: 86\n",
      "Code: 560, Description: The provider performs anesthesia services for a patient undergoing a procedure involving the heart, the sac around the heart, and the great vessels of the chest, such as the aorta, its major branches, and the major pulmonary vessels. The patient does not require a pump oxygenator to take on the work of the heart and lungs., Score: 86\n",
      "Code: 561, Description: The provider performs anesthesia services for a patient undergoing a procedure involving the heart, the sac around the heart, and the great vessels of the chest, such as the aorta, its major branches, and the major pulmonary vessels. The patient, who is younger than a year old, requires a pump oxygenator to take on the work of the heart and lungs during the procedure., Score: 86\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "# Function to find the most relevant CPT codes for the given input text\n",
    "def find_relevant_cpt_codes(pitch_text, cpt_data, top_n=5):\n",
    "    cpt_descriptions = cpt_data[\"Description\"].tolist()\n",
    "    # Find the top matches for the extracted text\n",
    "    matches = process.extract(pitch_text, cpt_descriptions, limit=top_n)\n",
    "    \n",
    "    # Get the corresponding codes and descriptions for the best matches\n",
    "    relevant_codes = []\n",
    "    for match in matches:\n",
    "        description = match[0]\n",
    "        score = match[1]\n",
    "        code = cpt_data[cpt_data['Description'] == description]['Code'].values[0]\n",
    "        relevant_codes.append({'Code': code, 'Description': description, 'Score': score})\n",
    "    \n",
    "    return relevant_codes\n",
    "\n",
    "relevant_codes = find_relevant_cpt_codes(pitch_text, cpt_data)\n",
    "\n",
    "# Display the relevant CPT codes\n",
    "for code in relevant_codes:\n",
    "    print(f\"Code: {code['Code']}, Description: {code['Description']}, Score: {code['Score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to find the most relevant CPT codes for the given input text using NER\n",
    "def find_relevant_cpt_codes(pitch_text, cpt_data):\n",
    "    # Process the extracted text with spaCy to identify named entities\n",
    "    doc = nlp(pitch_text)\n",
    "    \n",
    "    # Extract relevant entities (e.g., medical terms, procedures)\n",
    "    entities = [ent.text for ent in doc.ents if ent.label_ in ['MEDICAL_CONDITION', 'PROCEDURE']]\n",
    "    \n",
    "    # Find matching CPT codes based on the entities\n",
    "    relevant_codes = []\n",
    "    for entity in entities:\n",
    "        matches = cpt_data[cpt_data['Description'].str.contains(entity, case=False, na=False)]\n",
    "        for _, row in matches.iterrows():\n",
    "            relevant_codes.append({'Code': row['Code'], 'Description': row['Description']})\n",
    "    \n",
    "    return relevant_codes\n",
    "\n",
    "relevant_codes = find_relevant_cpt_codes(pitch_text, cpt_data)\n",
    "\n",
    "relevant_codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: 222, Description: The provider performs anesthesia services for a patient undergoing an intracranial procedure, including electrocoagulation of an intracranial nerve, which means to stop bleeding using electrocautery, or an electrical current.\n",
      "Code: 190, Description: The provider performs anesthesia services for a patient undergoing a procedure on the facial bones or the skull.\n",
      "Code: 192, Description: The provider performs anesthesia services for a patient undergoing radical surgery procedures on the facial bones or skull. This may include prognathism, which is a protrusion of the lower jaw.\n",
      "Code: 210, Description: The provider performs anesthesia services for a patient undergoing intracranial procedures that are not specifically described by another anesthesia code.\n",
      "Code: 211, Description: The provider performs anesthesia services for a patient undergoing intracranial procedures that involve removing a small portion of skull bone to take out a hematoma or blood clot from within the brain or tissues surrounding it.\n",
      "Code: 212, Description: The provider performs anesthesia services for a patient undergoing intracranial procedures involving subdural taps. In this procedure, another provider removes a little fluid from the subdural space, the fluid filled space in between the outer and middle membrane layers covering the brain. The surgical provider performs the procedure to decrease the excess intracranial fluid pressure being exerted on the brain tissues.\n",
      "Code: 214, Description: The provider performs anesthesia services for a patient undergoing intracranial procedures involving burr holes and possibly ventriculography.\n",
      "Code: 215, Description: The provider performs anesthesia services for a patient undergoing extradural intracranial procedures involving cranioplasty or raising a depressed skull fracture.\n",
      "Code: 216, Description: The provider performs anesthesia services for a patient undergoing intracranial vascular procedures.\n",
      "Code: 218, Description: The provider performs anesthesia services for a patient undergoing an intracranial procedure while in a sitting position.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Function to perform topic modeling using LDA to find the most relevant CPT codes\n",
    "def find_relevant_cpt_codes_lda(pitch_text, cpt_data, num_topics=3, num_words=5):\n",
    "    # Combine extracted text with CPT descriptions for LDA\n",
    "    corpus = cpt_data['Description'].tolist() + [pitch_text]\n",
    "    \n",
    "    # Convert the corpus into a document-term matrix\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    dtm = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    # Fit the LDA model\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    lda.fit(dtm)\n",
    "    \n",
    "    # Get the feature names (words)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Extract topics and words from the LDA model\n",
    "    topics = lda.components_\n",
    "    \n",
    "    # Find the topics related to the extracted text (last document in the corpus)\n",
    "    pitch_text_idx = len(corpus) - 1\n",
    "    text_topics = lda.transform(dtm[pitch_text_idx])\n",
    "    \n",
    "    # Get the top words for each topic\n",
    "    relevant_words = []\n",
    "    for topic_idx, topic in enumerate(topics):\n",
    "        top_words_idx = topic.argsort()[-num_words:][::-1]\n",
    "        relevant_words.extend([feature_names[i] for i in top_words_idx])\n",
    "    \n",
    "    # Find matching CPT codes based on the relevant words\n",
    "    relevant_codes = []\n",
    "    for word in set(relevant_words):\n",
    "        matches = cpt_data[cpt_data['Description'].str.contains(word, case=False, na=False)]\n",
    "        for _, row in matches.iterrows():\n",
    "            relevant_codes.append({'Code': row['Code'], 'Description': row['Description']})\n",
    "    \n",
    "    return relevant_codes\n",
    "\n",
    "# Example usage\n",
    "relevant_codes = find_relevant_cpt_codes_lda(pitch_text, cpt_data)\n",
    "\n",
    "# Display the relevant CPT codes\n",
    "# Display the relevant CPT codes (limit output)\n",
    "for code in relevant_codes[:5]:  # Display only the first 10 matches\n",
    "    print(f\"Code: {code['Code']}, Description: {code['Description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Matching\n",
    "Corpus: combine all CPT descriptions and pitch text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: 99375, Description: Report this service when the provider supervises the care provided by a home health agency, overseeing the plan of care, while the patient is at home or in a facility meant for long–term care. For 99375 the provider should spend 30 minutes or more on a patient’s indirect care., Score: 0.2989245353553636\n",
      "Code: 96156, Description: The provider assesses psychological, behavioral, emotional, cognitive, and social factors that affect a patient’s physical health, rather than assessing a specific mental health disorder. There are no time limits applied to this code. Report this code for an initial or repeat health behavior assessment., Score: 0.2739189946849235\n",
      "Code: 99493, Description: A provider performs psychiatric collaborative care management (CoCM) for a patient receiving behavioral health treatment and regular psychiatric interspecialty consultation in collaboration and in conjunction with a patient’s treating (or billing) primary care provider.?Report?99493?for the first 60 minutes of CoCM in a subsequent month after the first month of care.?, Score: 0.26222668207877176\n",
      "Code: 99494, Description: A provider performs psychiatric collaborative care management (CoCM) for a patient receiving behavioral health treatment and regular psychiatric interspecialty consultation whose conditions are not improving in collaboration and in conjunction with a patient’s treating (or billing) primary care provider. Report this code in addition to 99492 or 99493 for each additional 30 minutes of initial or subsequent psychiatric care management in a calendar month, in addition to the primary codes., Score: 0.25451629137495857\n",
      "Code: 99374, Description: Report this service when the provider oversees the plan of care provided by a home health agency while the patient is at home or in a facility meant for long–term care. For 99374 the provider should spend a minimum 15–29 minutes on a patient’s indirect care., Score: 0.2514539971821205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Corpus: combine all CPT descriptions and pitch text\n",
    "# Function to perform TF-IDF matching to find the most relevant CPT codes\n",
    "def find_relevant_cpt_codes_tfidf(pitch_text, cpt_codes_df, top_n=5):\n",
    "    # Combine extracted text with CPT descriptions for TF-IDF\n",
    "    corpus = cpt_data['Description'].tolist() + [pitch_text]\n",
    "    \n",
    "    # Convert the corpus into a TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    # Calculate cosine similarity between the extracted text and all CPT descriptions\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()\n",
    "    \n",
    "    # Get the indices of the top matches\n",
    "    top_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # Get the corresponding codes and descriptions for the best matches\n",
    "    relevant_codes = []\n",
    "    for idx in top_indices:\n",
    "        relevant_codes.append({\n",
    "            'Code': cpt_data.iloc[idx]['Code'],\n",
    "            'Description': cpt_data.iloc[idx]['Description'],\n",
    "            'Score': cosine_similarities[idx]\n",
    "        })\n",
    "    \n",
    "    return relevant_codes\n",
    "\n",
    "relevant_codes = find_relevant_cpt_codes_tfidf(pitch_text, cpt_data)\n",
    "\n",
    "# Display the relevant CPT codes\n",
    "for code in relevant_codes:\n",
    "    print(f\"Code: {code['Code']}, Description: {code['Description']}, Score: {code['Score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus: combine description for the CPT in this row and pitch text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: 99375, Description: Report this service when the provider supervises the care provided by a home health agency, overseeing the plan of care, while the patient is at home or in a facility meant for long–term care. For 99375 the provider should spend 30 minutes or more on a patient’s indirect care., Score: 0.2920122671021555\n",
      "Code: 99493, Description: A provider performs psychiatric collaborative care management (CoCM) for a patient receiving behavioral health treatment and regular psychiatric interspecialty consultation in collaboration and in conjunction with a patient’s treating (or billing) primary care provider.?Report?99493?for the first 60 minutes of CoCM in a subsequent month after the first month of care.?, Score: 0.2581073391292682\n",
      "Code: 99374, Description: Report this service when the provider oversees the plan of care provided by a home health agency while the patient is at home or in a facility meant for long–term care. For 99374 the provider should spend a minimum 15–29 minutes on a patient’s indirect care., Score: 0.25004135525376137\n",
      "Code: 99494, Description: A provider performs psychiatric collaborative care management (CoCM) for a patient receiving behavioral health treatment and regular psychiatric interspecialty consultation whose conditions are not improving in collaboration and in conjunction with a patient’s treating (or billing) primary care provider. Report this code in addition to 99492 or 99493 for each additional 30 minutes of initial or subsequent psychiatric care management in a calendar month, in addition to the primary codes., Score: 0.2332112696918336\n",
      "Code: 99379, Description: Report this service when the provider supervises the care provided at a nursing facility, overseeing the plan of care. For 99379 the provider should spend 15–29 minutes on the patient’s indirect care., Score: 0.2296355969872238\n"
     ]
    }
   ],
   "source": [
    "def find_relevant_cpt_codes_tfidf(pitch_text, cpt_data, top_n=5):\n",
    "    # Create a list to store similarity scores\n",
    "    relevant_codes = []\n",
    "    \n",
    "    # Corpus: combine description for the CPT in this row and pitch text\n",
    "    # Iterate through each CPT description to compare with the extracted text\n",
    "    for index, row in cpt_data.iterrows():\n",
    "        corpus = [row['Description'], pitch_text]\n",
    "        \n",
    "        # Convert the corpus into a TF-IDF matrix\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "        \n",
    "        # Calculate cosine similarity between the extracted text and the CPT description\n",
    "        cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]).flatten()[0]\n",
    "        \n",
    "        # Append the code, description, and similarity score\n",
    "        relevant_codes.append({\n",
    "            'Code': row['Code'],\n",
    "            'Description': row['Description'],\n",
    "            'Score': cosine_sim\n",
    "        })\n",
    "    \n",
    "    # Sort the relevant codes by similarity score in descending order and return the top matches\n",
    "    relevant_codes = sorted(relevant_codes, key=lambda x: x['Score'], reverse=True)[:top_n]\n",
    "    return relevant_codes\n",
    "\n",
    "relevant_codes = find_relevant_cpt_codes_tfidf(pitch_text, cpt_data)\n",
    "\n",
    "# Display the relevant CPT codes\n",
    "for code in relevant_codes:\n",
    "    print(f\"Code: {code['Code']}, Description: {code['Description']}, Score: {code['Score']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
